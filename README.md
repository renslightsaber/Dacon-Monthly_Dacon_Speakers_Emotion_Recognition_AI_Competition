# [[í˜„ì¬ ê³µì‚¬ ì¤‘]ğŸ…[Dacon] ì›”ê°„ ë°ì´ì½˜ ë°œí™”ìì˜ ê°ì •ì¸ì‹ AI ê²½ì§„ëŒ€íšŒ](https://dacon.io/competitions/official/236027/overview/description)
<img src="/img/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2023-03-11 á„‹á…©á„’á…® 2.47.15.png" width="99%"></img>
## Competition Info
 - Period: 2022.11.01 - 2022.12.12
 - Joined as: Team with [A.RYANG](https://github.com/nomaday)
 - TEAM_NAME: 'ë§í•˜ê¸°ì „ì—ìƒê°í–ˆë‚˜ìš”?'
 - TASK: `Classification`
 - Evaluation Metric: `Macro F1 Score`
 - Environment: Colab 
 
## Result "ğŸ… Prized as 5th"
 - PUBLIC  : 0.54517 | 11st /259 
 - PRIVATE : 0.54712 | 10th /259 
 - Final: 5th 
 
### ìˆ˜ìƒì¸ì¦ì„œ
<img src="/img/1673529536217.jpeg" width="48%"></img>

-----------------
 
 
## install
#### [torchmetrics](https://torchmetrics.readthedocs.io/en/stable/)
```python
$ pip install -qqq torchmetrics
```

#### [colorama](https://github.com/tartley/colorama)
```python
$ pip install -qqq colorama
```

#### HuggingFace Transformer
```python
$ pip install -qqq --no-cache-dir transformers sentencepiece
```


## [linkë„ ê³µì‚¬ì¤‘] How to train or inference in CLI? [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1EPaUyBIP4VER23AKPoLBPjW-Gdn8Bv6b?usp=share_link)


### Train 
```python

$ python train.py --base_path './data/' \
                  --model_save '/content/drive/MyDrive/á„€á…µá†ºá„’á…¥á†¸/Projects/Dacon Speakers/' \
                  --sub_path '/content/drive/MyDrive/á„€á…µá†ºá„’á…¥á†¸/Projects/Dacon Speakers/' \
                  --model "monologg/kobigbird-bert-base" \
                  --add_speaker_info True\
                  --make_essay_option True\
                  --make_essay_sentences 4\
                  --grad_clipping True\
                  --n_folds 5 \
                  --n_epochs 5 \
                  --device 'cuda' \
                  --train_bs 16
  
``` 
- `base_path` : Dataê°€ ì €ì¥ëœ ê²½ë¡œ (Default: `./data/`)
- `sub_path`  : `submission.csv` ì œì¶œí•˜ëŠ” ê²½ë¡œ
- `model_save`: í•™ìŠµëœ ëª¨ë¸ì´ ì €ì¥ë˜ëŠ” ê²½ë¡œ
- `clean_text`: `mecab` tokenizerë¡œ ë°ì´í„°ë¥¼ tokenize ì‹œì¼°ë‹¤ê°€ ë‹¤ì‹œ `" ".join`ìœ¼ë¡œ ë³µì›ì‹œí‚¬ ê²ƒì— ëŒ€í•œ ì—¬ë¶€
- `test_and_ss`: `test.csv`, `sample_submission.csv`íŒŒì¼ì„ ì‚¬ìš© ì—¬ë¶€
- `model`: Huggingfaceì˜ Pratrained Model (Default: `"tae898/emoberta-base"`)
- `add_speaker_info`: `Speaker`ë¥¼ ëŒ€ë¬¸ìí™” ì‹œí‚¨ í›„ `Utterance`ì™€ ê²°í•© (`Speaker`.upper() + `:` + `Utterance`)
- `make_essay_option`: ì´ì „ Nê°œì˜ indexì˜ `Utternce`ë“¤ê³¼ í˜„ì¬ indexì˜ `Utterance`ë¥¼ ê²°í•© ([`utils.py`](https://github.com/renslightsaber/Dacon_Speakers_Emotion_Recognition/blob/main/utils.py) ì°¸ê³ )
  - `make_essay_sentences`: ê²°í•©í•  ì´ì „ `Utternce`ë“¤ì˜ ìˆ˜(= N)
- `n_folds`  : Fold ìˆ˜
- `n_epochs` : Epoch
- `seed` : Random Seed (Default: 2022)
- `train_bs` : Batch Size (Default: 16)
- `max_length` : Max Length (Default: 128) for HuggingFace Tokenizer
- `grad_clipping`: [Gradient Clipping](https://neptune.ai/blog/understanding-gradient-clipping-and-how-it-can-fix-exploding-gradients-problem)
- `ratio` : ë°ì´í„°ë¥¼ Splití•˜ì—¬ `train`(í•™ìŠµ) ê³¼ `valid`(ì„±ëŠ¥ í‰ê°€)ë¥¼ ë§Œë“œëŠ” ë¹„ìœ¨ì„ ì˜ë¯¸. ì •í™•íˆëŠ” `train`ì˜ Size ê²°ì •
- `device`: GPUë¥¼ í†µí•œ í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤ë©´, `cuda` ë¡œ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.
- `learning_rate`, `weight_decay`, `min_lr`, `T_max` ë“±ì€ ìƒëµ 

- [`train.py`](https://github.com/renslightsaber/Dacon_Speakers_Emotion_Recognition/blob/main/train.py) ì°¸ê³ !   


### ì£¼ì˜
 - CLI í™˜ê²½ì—ì„œ train ì‹œí‚¬ ë•Œ, `tqdm`ì˜ Progress Barê°€ ì—„ì²­ ë§ì´ ìƒì„±ëœë‹¤. ì•„ì§ ì›ì¸ê³¼ í•´ê²°ì„ ëª» ì°¾ì€ ìƒíƒœì´ë‹¤.
 - Colabê³¼ Jupyter Notebookì—ì„œëŠ” ì •ìƒì ìœ¼ë¡œ Progress Barê°€ ë‚˜íƒ€ë‚œë‹¤.


### Inference 
```python

$ python inference.py --base_path './data/' \
                      --model_save '/content/drive/MyDrive/ ... /Dacon Speakers/' \
                      --sub_path '/content/drive/MyDrive/ ... /Dacon Speakers/' \
                      --model "monologg/kobigbird-bert-base" \
                      --add_speaker_info True\
                      --make_essay_option True\
                      --make_essay_sentences 4\
                      --n_folds 5 \
                      --n_epochs 5 \
                      --device 'cuda' \
                      --train_bs 16

```
- `base_path` : Dataê°€ ì €ì¥ëœ ê²½ë¡œ (Default: `./data/`)
- `sub_path`  : `submission.csv` ì œì¶œí•˜ëŠ” ê²½ë¡œ
- `model_save`: í•™ìŠµëœ ëª¨ë¸ì´ ì €ì¥ë˜ëŠ” ê²½ë¡œ
- `model`: Huggingfaceì˜ Pratrained Model (Default: `"monologg/kobigbird-bert-base"`)
- `n_folds`  : `train.py`ì—ì„œ ì§„í–‰í•­ KFold ìˆ˜
- `n_epochs` : trainí–ˆì„ ë•Œì˜ Epoch ìˆ˜ (submission íŒŒì¼ëª…ì— ì‚¬ìš©)  
- `device`: GPUë¥¼ í†µí•œ í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤ë©´, `cuda` ë¡œ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.


#### [linkë„ ê³µì‚¬ì¤‘]Jupyter Notebook Version: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mB05pvu7d83KQX6dyYlj4jxdeUSEt7pJ?usp=sharing) 



